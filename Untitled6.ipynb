{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d2e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c1a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3351bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7887a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9410b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clas SGAE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3):\n",
    "        super().__init__()\n",
    "     \n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            xs = []\n",
    "            x_target = x[:size[1]]\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers -1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "            xs.append(x)\n",
    "            if i == 0:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_1_embeddings = x_all\n",
    "            elif i == 1 :\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_2_embeddings = x_all\n",
    "            elif i == 2:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_3_embeddings = x_all\n",
    "        # return x.log_softmax(dim=-1)\n",
    "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
    "    \n",
    "    def inference(self, x_all):\n",
    "        pbar = tqdm(total=x_all.size(0)*self.num_layers)\n",
    "        pbar.set_description(\"Evaluating\")\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            xs = []\n",
    "            for batch_size, n_id, adj in subgraph_loader:\n",
    "                \n",
    "                edge_index, _, size = adj.to(device)\n",
    "                total_edges += edge_index.size(1)\n",
    "                \n",
    "                \n",
    "\n",
    "                if i == 0:\n",
    "                    x_all = torch.cat(xs, dim=0)\n",
    "                    layer_1_embeddings = x_all\n",
    "                elif i==1:\n",
    "                    x_all = torch.cat(xs, dim=0)\n",
    "                    layer_2_embeddings = x_all\n",
    "                elif i==2:\n",
    "                    x_all = torch.cat(xs,dim=0)\n",
    "                    layer_3_embeddings = x_all\n",
    "                \n",
    "        pbar.close()\n",
    "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93fe807",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(dataset.num_features, 256, data.num_classes, num_layers)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading node feature matrix and node labels\n",
    "x = data.x.to(device)\n",
    "y = data.y.squeeze().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = total_correct = 0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        \n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l1_emb, l2_emb, l3_emb = model(x[n_id], adjs)\n",
    "        \n",
    "        out = l3_emb.log_softmax(dim=-1)\n",
    "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss)\n",
    "        total_correct += int(out.argmax(dim=-1)eq(y[n_id[:batch_size]]).sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = total_loss/len(train_loader)\n",
    "    approx_acc = total_correct /train_idx.size(0)\n",
    "    return loss, approx_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03354b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d448340",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(21):\n",
    "    loss, acc = train(epoch)\n",
    "    print(f\"Epoch {epoch} Loss: {loss:.4f}, Accuracy {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_parameter = count_parameters(model)\n",
    "print(total_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model state dict: \")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949dca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c77d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be489bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=l2_reduced_emb[:, 0], y=l2)\n",
    "plt.legend(bbox_to_anchor=(1.05,1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865e242",
   "metadata": {},
   "source": [
    "### Layer-3 Node Embeddings visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6405598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample test data\n",
    "l3_emb_sample = l3_embedding_test[:2000].detach().cpu().numpy()\n",
    "\n",
    "y_pred_sample = y_pred[:2000]\n",
    "l3_emb_sample.shape, y_pred_sample.shape\n",
    "l3_reduced_emb = reducer.fit_transform(l3_emb_sample)\n",
    "\n",
    "plt.scatter(x = l3_reduced_emb[:,0], y=l3_reduced_emb[:,1], hue=y_pred_sample_products, palette=color_coding)\n",
    "plt.legend(bbox_to_anchor=(1.05,1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968cd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf677b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77465893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005afda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7a953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fd092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a1d5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_attribute read by read_csv\n",
    "# select column hashedid, company_type, position_type\n",
    "# node_attr = node_attr[[\"\"]]\n",
    "# check info\n",
    "# reassign set_index\n",
    "# attribute dict\n",
    "# node_attr.to_dict(orient=\"index\")\n",
    "# attribute_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9605854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json\n",
    "# candidate json object as dictionary\n",
    "\n",
    "# open and load\n",
    "# adjacencies_from_candidate_referrals \n",
    "\n",
    "# closing file\n",
    "# candidate_link_file.close()\n",
    "\n",
    "# check length\n",
    "\n",
    "# len(set(adjacencies_from_candidate_referrals.keys()))\n",
    "\n",
    "\n",
    "# create Edge list and Adjacency list\n",
    "\n",
    "def create_adjacency_list(data_dict, suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Input: a. a dictionary of candidate referrals where the keys are \n",
    "                are members who have referred other candidates, and \n",
    "                the values are lists of the people who where referred.\n",
    "            b. a suffix to append to the file name\n",
    "            \n",
    "    output: i. an encoded adjacency list in a text file\n",
    "            ii. a list of the node IDs found\n",
    "    \"\"\"\n",
    "    list_of_nodes = []\n",
    "    \n",
    "    for source_node in list(data_dict.keys()):\n",
    "        \n",
    "        if source_node not in list_of_nodes:\n",
    "            list_of_nodes.append(souce_node)\n",
    "            \n",
    "        for y in data_dict[source_dict]:\n",
    "            \n",
    "            if source_node not in list_of_nodes:\n",
    "                list_of_nodes.append(y)\n",
    "            if y not in data_dict.keys():\n",
    "                data_dict[y] = [source_node]\n",
    "            else:\n",
    "                if source_node not in data_dict[y]:\n",
    "                    data_dict[y].append(source_node)\n",
    "                else:\n",
    "                    contnue\n",
    "    \n",
    "    g = open(\"adjacency_list_{}.txt\".format(suffix), \"w+\")\n",
    "    \n",
    "    for source_node in list(data_dict.keys()):\n",
    "        dt = \" \".join(data_dict[source_node])\n",
    "        g.write(\"{} {} \\n\".format(source_node, dt))\n",
    "    \n",
    "    g.close()\n",
    "    \n",
    "    \n",
    "    print(len(list_of_nodes))\n",
    "    return list_of_nodes, data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d953b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_nodes_adj, candidate_dict = create_adjacency_list(adjacencies_from_candidate_referrals, \"candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a140254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_nodes_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798cff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_from_adj = nx.read_adjlist(\"adjacency_list_candidate.txt\")\n",
    "graph_from_adj.number_of_edges(), graph_from_adj.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edge list\n",
    "\n",
    "def create_edge_list(data_dict, suffix=\"\"):\n",
    "    edge_list_file = open(\"edge_list_{}.txt\".format(suffix), \"w+\")\n",
    "    list_of_edges = []\n",
    "    list_of_nodes_all = []\n",
    "    \n",
    "    for source_node in list(data_dict.keys()):\n",
    "        if source_node not in list_of_nodes_all:\n",
    "            list_of_nodes_all.append(source_node)\n",
    "        list_of_connects = data_dict[source_node]\n",
    "        \n",
    "        for destination_node in list_of_connects:\n",
    "            if destination_node not in list_of_nodes_all:\n",
    "                list_of_nodes_all.append(destination_node)\n",
    "                \n",
    "            if {source_node, destination_node} not in list_of_edges:\n",
    "                print()\n",
    "                edge_list_file.write(\"{} {} \\n\".format(source_node, destination_node))\n",
    "                list_of_edges.append({source_node, destination_node})\n",
    "            else:\n",
    "                continue\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
