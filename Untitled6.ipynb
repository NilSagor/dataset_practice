{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d2e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c1a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3351bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074bd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7887a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9410b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clas SGAE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3):\n",
    "        super().__init__()\n",
    "     \n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            xs = []\n",
    "            x_target = x[:size[1]]\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "            if i != self.num_layers -1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "            xs.append(x)\n",
    "            if i == 0:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_1_embeddings = x_all\n",
    "            elif i == 1 :\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_2_embeddings = x_all\n",
    "            elif i == 2:\n",
    "                x_all = torch.cat(xs, dim=0)\n",
    "                layer_3_embeddings = x_all\n",
    "        # return x.log_softmax(dim=-1)\n",
    "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings\n",
    "    \n",
    "    def inference(self, x_all):\n",
    "        pbar = tqdm(total=x_all.size(0)*self.num_layers)\n",
    "        pbar.set_description(\"Evaluating\")\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            xs = []\n",
    "            for batch_size, n_id, adj in subgraph_loader:\n",
    "                \n",
    "                edge_index, _, size = adj.to(device)\n",
    "                total_edges += edge_index.size(1)\n",
    "                \n",
    "                \n",
    "\n",
    "                if i == 0:\n",
    "                    x_all = torch.cat(xs, dim=0)\n",
    "                    layer_1_embeddings = x_all\n",
    "                elif i==1:\n",
    "                    x_all = torch.cat(xs, dim=0)\n",
    "                    layer_2_embeddings = x_all\n",
    "                elif i==2:\n",
    "                    x_all = torch.cat(xs,dim=0)\n",
    "                    layer_3_embeddings = x_all\n",
    "                \n",
    "        pbar.close()\n",
    "        return layer_1_embeddings, layer_2_embeddings, layer_3_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93fe807",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAGE(dataset.num_features, 256, data.num_classes, num_layers)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading node feature matrix and node labels\n",
    "x = data.x.to(device)\n",
    "y = data.y.squeeze().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = total_correct = 0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        \n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l1_emb, l2_emb, l3_emb = model(x[n_id], adjs)\n",
    "        \n",
    "        out = l3_emb.log_softmax(dim=-1)\n",
    "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss)\n",
    "        total_correct += int(out.argmax(dim=-1)eq(y[n_id[:batch_size]]).sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    loss = total_loss/len(train_loader)\n",
    "    approx_acc = total_correct /train_idx.size(0)\n",
    "    return loss, approx_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03354b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d448340",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(21):\n",
    "    loss, acc = train(epoch)\n",
    "    print(f\"Epoch {epoch} Loss: {loss:.4f}, Accuracy {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d14b9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_parameter = count_parameters(model)\n",
    "print(total_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model state dict: \")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949dca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c77d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be489bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c24f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=l2_reduced_emb[:, 0], y=l2)\n",
    "plt.legend(bbox_to_anchor=(1.05,1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b865e242",
   "metadata": {},
   "source": [
    "### Layer-3 Node Embeddings visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6405598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample test data\n",
    "l3_emb_sample = l3_embedding_test[:2000].detach().cpu().numpy()\n",
    "\n",
    "y_pred_sample = y_pred[:2000]\n",
    "l3_emb_sample.shape, y_pred_sample.shape\n",
    "l3_reduced_emb = reducer.fit_transform(l3_emb_sample)\n",
    "\n",
    "plt.scatter(x = l3_reduced_emb[:,0], y=l3_reduced_emb[:,1], hue=y_pred_sample_products, palette=color_coding)\n",
    "plt.legend(bbox_to_anchor=(1.05,1), loc=2, borderaxespad=0.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
